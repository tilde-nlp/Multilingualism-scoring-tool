[app]
#LOG_DATEFORMAT = %Y-%m-%d %H:%M:%S
#LOG_ENCODING = utf-8
#LOG_FILE = app.log
#LOG_FORMAT = %(asctime)s [%(name)s] %(levelname)s: %(message)s
##LOG_FORMAT = %(asctime)s %(message)s
#LOG_LEVEL = WARNING 
#CRITICAL ERROR WARNING INFO DEBUG NOTSET
SAVED_RESULTS_DIR = saved_results

[crawler]
# Scrapy settings
# Settings per-spider https://docs.scrapy.org/en/latest/topics/settings.html
BOT_NAME = Multilinguality scoring bot
CONCURRENT_REQUESTS = 16
CONCURRENT_REQUESTS_PER_DOMAIN = 1
# The maximum depth that will be allowed to crawl for any site. If zero, no limit will be imposed.
DEPTH_LIMIT = 5

# As depth increases, positive values of DEPTH_PRIORITY decrease request priority (BFO - breadth first order), 
# while negative values increase request priority (DFO - depth first order). 
# settings['DEPTH_PRIORITY'] = 1
DEPTH_PRIORITY = 1
DEPTH_STATS_VERBOSE = True
DOWNLOAD_DELAY = 0.5

#The maximum response size (in bytes) that downloader will download. 16*1024*1024  = 16777216
DOWNLOAD_MAXSIZE = 16777216
#The response size (in bytes) that downloader will start to warn. 2*1024*1024 = 2097152
DOWNLOAD_WARNSIZE = 2097152
# Disable cache for testing
HTTPCACHE_ENABLED = False 
HTTPCACHE_POLICY = scrapy.extensions.httpcache.RFC2616Policy

LOG_FILE = spider.log
LOG_LEVEL = DEBUG 
REACTOR_THREADPOOL_MAXSIZE = 20
ROBOTSTXT_OBEY = True
SCHEDULER_DISK_QUEUE = scrapy.squeues.PickleFifoDiskQueue
SCHEDULER_MEMORY_QUEUE = scrapy.squeues.FifoMemoryQueue
SCHEDULER_PRIORITY_QUEUE = scrapy.pqueues.DownloaderAwarePriorityQueue
TELNETCONSOLE_ENABLED = False
USER_AGENT = Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36

[analyzer]
data_dir = analyzed_data
